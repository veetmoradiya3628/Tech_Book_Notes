

- #### Why an OS?
	- The operating system is Software
	- Abstract layer over Hardware
	- Apps talk to the OS
	- Most OSs are general-purpose
    - Scheduling
	- CPU / Memory and IO
    - Idea: Job scheduling software that's all
    - OS APIs abstract the hardware
    - Can you build your app without an OS?
    - OS shouldn’t be a black box
    - Kernel manages resources
    - CPU
	    - Central Processing Unit
	    - Consists of cores
	    - Each core has a clock speed
	    - Executes machine-level instructions
	    - Fast caches
    - Memory
	    - RAM - Random Access Memory
	    - Fast but volatile
	    - Store processes, states, and data
	    - Limited
	    - Slower than CPU Cache
    - Storage
	    - Persisted storage
	    - HDD, SSD
	    - Slower than memory
	- Network
	    - TCP IP offload engine
	    - Communicates with other hosts
	    - NIC - Network Interface Controller
	    - Protocol implementations
    - Kernal
	    - The core of the OS
	    - Manages the resources
	    - The OS is more than the kernel
			- GUI, command line, UI, and tooling    
			- E.g., top is a tool that extracts and processes
			- Distros are all about this extra tooling   
	- File System
	    - Storage is primarily blocks of bytes
	    - We like to work on files
	    - The file system is an abstraction
	    - LBA - logical block addressing
	    - How are files stored on disk
	    - btrfs, ext4, fat32, NTFS, tmpfs
	- Program vs Process
	    - A program is the compiled executable
	    - Process is an instance of the program
	    - Process is a program in motion
	    - A program is a process at rest
	    - Execution file format
    - User Space vs Kernel Space
    	- User space
		    - Browser
		    - Postgres
	    - Kernel space
		    - Kernel code
		    - Device drivers
		    - TCP/IP stack
		- Isolated (io_uring kind of broke that rule)
	- Process management    
	- Device drivers
    - System calls
  

- #### Anatomy of a Process

- Program vs. Process
    - Process is a Program in motion
    - Code is compiled and linked for a CPU, and calls Program.
	- Static linking vs. Dynamic linking    
	- DLLs    
	- Only works on that CPU architecture
- Process
	   - When a program is run, we get a process
    - Process lives in memory
    - Uniquely identified with an id
    - Instruction pointer/program counter
    - Process control block (PCB)
- Code -> Assembly -> Machine Code
- Demo: Spin a process in Linux
	- gcc -S test.c test.s    
	- gcc -g test.c -o test
	 - gdb test
	    - Start
		- -n   

- Simple process execution

	- Machine code is often read from bottom to top, from low address to high address
	- Program counter steps, line-by-line instruction execution from memory and registry.
    - PC points to the current/next instructions
    - Fetch, Load, Execute cycle!

- The stack
	   - The stack is used for function calls
    - Stack pointer
    - Base pointer (Frame pointer)
    - Program counter
    - Previous base pointer
    - Return address 
	- Link register (LR)
- Process execution with Stack
- Data Section
	- Fixed size, Global and static variables, all functions share
    - Read and Write
    - Watch out for concurrency
- The Heap
    - Large, Dynamic place for memory allocations
	- Stores large data
	- Remain until explicitly removed
	- All functions can access
	- Dynamic, grows low to high
	- malloc, free, new
	- Pointers
		- Points to a memory address in the heap
		- A pointer can in stack, data or heap
		- Stores the address of first byte
		- Pointer type helps determine size
		- Heap is random
		- Stack space limited
		- Cache locality in stack
	- What is escape analysis ??
		- compiler optimization technique
	- Program break
		- where the process ends
		- Points to the top of the heap
		- Not recommended now its replaced with mmap
	- Slab memory allocation 

- Process demo :-

```
cat /proc/<pid>/maps 

sudo cat /proc/204/maps
```

- #### Memory Management

	- SRAM, DRAM, SDRAM, DDR Ram, Virtual Memory
	- What is Memory ?
		- Stores data
		- Volatile
			- RAM - Random access memory
		- Non-Volatile
			- ROM - Read Only Memory
	- SRAM 
		- Static RAM, Complex, expensive but fast
		- 1 bit -> 1 flip flop -> 6 transistors
		- constant power
		- Used it CPU caches, SSDs
	- DRAM
		- Dynamic RAM, cheaper, slower
		- 1 bit -> 1 capacitor, 1 transistor
		- Capacitors, lose their state
		- need to be refreshed
	- Double Data Rate RAMs
	- DDR4 vs DDR5 SDRAM
	- burst
	- prefetch buffer io
	- channels
	- DRAM internals
		- DIMM, Bank, Rows, Columns, Cells (1 cell 1 bit)
	- MMU - Memory management unit
	- Read from memory to CPU cache / RAM will happen via 64 bytes block not as a single instruction
	- Sense amplifier is write ahead logging concept in RAM concept
	- Data types are aligned
		- 1, 4 or 8 bytes 
		- Certain sizes are placed in specific addresses
	- Memory access takes 50 - 100 ns
	- Virtual Memory
		- Limitations of physical memory
			- Fragmentation
				- One space, memory must be contiguous
				- External vs. Internal fragmentation
				- Fixed size block allocation
			- Shared Memory
				- Shared libraries
					- Most processes uses libraries
					- OS loads the library code once
					- Map the virtual page to the library physical code
					- Libc
					- /proc/[pid]/maps
				- CoW - copy on write concept
			- Isolation
			- Large programs
				- Swaps
		- fixed block size call it paging
		- page size is often 4kb
		- Virtual memory and fragmentation
		- Page Tables
		- MMU & TLB
	- DMA
		- Direct Memory Access
		- Data from network / disk must pass through CPU (Peripherals Read)
		- DMA allows direct access from network / disk to RAM, works with directly with physical address since there is no MMU available from CPU.
		- IOMMU (allows IO) with virtual address
	- Virtual Memory space is dedicated to process but threads share the virtual memory space.

- #### Inside the CPU
	- Basic components
		- ALU (Arithmetic logic unit)
		- CU (Control Unit)
		- MMU (Memory management Unit)
		- Registers
		- Caches (L1, L2, L3)
		- Bus
	- One processer can have more than 1 core, generally in power of 2
	- L1 private cache for core
	- L3 cache is shared across the CORES
	- processor is connected to main memory via Bus
	- DSM - Distributed shared memory, Non uniform memory access (NUMA)
	-  ALU
		- Arithmetic - + - / *
		- XOR/OR/AND
		- Core of compute
	- CU
		- Control Unit
		- Fetches instructions
		- Decodes instructions
		- Executes instructions
	- Registers
		- Smallest ultrafast unit of storage
			- 32 or 64 bit
		- In the CPU core
		- Many registers types
		- PC, IR, SP, BP
		- General purpose
	- MMU
		- Memory management unit
		- Responsible for memory access
		- Translating virtual to physical address
			- TLB - Translation lookaside buffer
			- TLB must* be flushed on context switch
	- L caches
		- L1, L2 and L3
		- L1 - 1 ns, ~128 KB
		- L2 - 5 ns, ~256-2 MB
		- L3 shared - 15 ns, ~64 MB
		- Main Memory - 50-100 ns
		- Cache invalidation challenges
		- Some CPUs only have L1, and L2 (shared)
		- L1 cache is two types
			- L1D (data) 
			- L1I (Instructions)
			- CU can fetch data and instructions at same time
	- RISC
		- Reduced Instruction set
		- Simple instructions - each single task - single task
		- Low power, predictable
		- Use registers
		- Arm
	- CISC
		- Complex Instruction set
		- One instruction, lots of tasks, multiple cycle
		- More power, unpredictable
		- x86 (Intel/AMD)
	- Example of CISC vs. RISC
		- a = a + b
		- CISC
			- 1 instruction
			- ADD a, b
		- RISC 
			- 4 instruction
			- LDR r0, a
			- LDR r1, b
			- ADD r0, r1
			- STR a1, r0
	- Clock speed
		- How many cycles per second
		- e.g. 3 GHz - 3 billion clock cycles per second
		- in RISC could mean 3 billion per second but less in CISC
		- cost of fetching / decoding (pipelining helps)
	- Commands
		- show L caches
			- `sysctl -a | grep cachesize`
		- show number of cores
			- `sysctl -n hw.physicalcpue`
		- show CPU architecture
			- `uname -m`
	
	- Instruction Life Cycle
		- Fetch, Decode, Execute, Read, Write
		- Instruction
			- Fetch from memory (MMU)
			- Decode (CU)
			- Execute (ALU)
			- Memory read (optional)
			- Write (to register / memory)-
	- Pipelining and Parallelism
		- Notice how parts of the CPU are mostly idle
		- Pipelining helps
		- While decoding, we can fetch another instruction
		- While ALU executing, we can decode another instruction
		- Pipeline applies to the HTTP as well (HTTP post 1.1)
	- Parallelism
		- App can spin multiple processes/threads
		- Each go into it in a CPU core
	- Hyper threading
		- Sharing cores
		- Hyper threading exposes a single core as multiple logical cores
		- Dedicated registers (e.g. PC) shared CU/ALU/L cache
	- SIMD
		- Single instruction multiple data
		- With a single instruction add multiple values
		- Vectors
		- Gaming / DB Btrees
		- E.g. ARM Neon
	- Workload identification for backend applications or any applications
		- IO bound
		- CPU bound

- #### Process Management
 - A dive into process
 - Process vs. Thread
	 - Process
		 - An instance of a program
		 - Has dedicated code, stack, heap, data section
		 - Has context in the CPU (pc, lr, etc...)
		 - Process Control Block
	 - PCB
		 - Kernel needs metadata about the process
		 - PCB Contains
			 - PID, process state, pc, registers
			 - process control info
			 - page table
			 - Accounting (CPU/Memory usage)
			 - Memory management info (pointer to code / stack etc.)
			 - IO info (FDs)
			 - IPC, semaphores, mutexes, shared memory, messages etc.
	 - Kernel process table
		 - Kernel needs to manage processes
		 - A mapping table from PID to PCB
		 - Process table
		 - Quick lookup
		 - In kernel space
	 - Thread
		 - A thread is a light weight process
		 - Shared code/heap, data and PCB
		 - Stack is different and PC
		 - Thread stack lives in same VM
	 - Thread control block
		 - Kernel needs metadata about the threads
		 - TCB contains
			 - TID, Thread state, PC, registers
			 - Process control info 
			 - Accounting
			 - Memory management info (Pointer to stack etc.)
			 - Pointer to parent PCB
	 - Kernel Thread table
		 - Kernel needs to manage threads
		 - A mapping table from TID to TCB
		 - Thread table
		 - Quick lookup
		 - In kernel space
	 - Shared memory
		 - Multiple processes / threads can share memory
		 - mmap
		 - Virtual memory different, physical memory same
		 - Shared buffers in databases
	 - Fork
		 - Fork creates a new process
		 - Child must have new virtual memory
		 - But OS uses CoW so pages can be shared unless a write happens
		 - Redis Asynchronous durability
	 - Summary
		 - Processes have dedicated VM
		 - Threads belong to the same process
		 - Threads share parent process memory
	
 - Context Switching
	 - CPU Process
		 - CPU doesn't really know what a process is
		 - OS loads data into CPU registers (pc, sp, bp, etc.)
		 - Pointer to Page Table mapping (ptbr - page table base register)
		 - Called "context"
		 - Executes instructions
	 - Context switch
		 - To switch context we save current context and load new context
		 - Save the current registers to current process PCB (memory write)
		 - Load the new process PCB to CPU registers (memory read)
		 - pc, bp, sp, lr, ptbr and more
	 - TLB flush
		 - TLB stores virtual memory mapping cache
		 - Slow
		 - processes CANNOT share VM mapping
		 - Threads of same process are faster to switch
			 - Same memory, paging
			 - As long as threads of the same process
	 - TLB ASID
	 - When does context switch happens
		 - Scheduling algorithms
		 - Preemptive multitasking
		 - IO Wait
	 - Preemptive multitasking
		 - Some processes run for a long time
		 - OS must switch those out
		 - Time slice
		 - Windows 3.1 bug where other processes starve
	 - Scheduling algorithms
		 - FCFS
		 - SJF
		 - Round robin
 - Concurrency
	 - Split your program into processes or threads
	 - CPU time is precious, its commodity, need to keep it busy, can one task be split to concurrent tasks
	 - CPU bound vs. IO bound workload
		 - CPU bound
			 - Encryption, Compression, DB planning, sorting, Protocol parsing (HTTP/2, QUIC)
			 - we want to limit starvation of those
		 - IO bound
			 - Database queries, network connection write/read, file reads/writes
	 - Multi-threaded vs. Multi-process
		 - Multi-process
			 - Spin multiple processes
			 - Isolated
			 - e.g. NGINX, Postgres
		 - Multi-threaded
			 - parent process spins multiple threads
			 - Share memory with parent
			 - e.g. MySQL, Libuv
	 - Challenges
		 - Thread safety
	 - Mutexes
		 - Mutex is binary lock (mutual exclusion)
		 - One thing at a time
	 - Mutex Gotchas
		 - Mutex has ownership
		 - The thread that locks mutex must unlock
		 - if a thread terminates the mutex can remain locked
		 - can cause deadlock
		 - Two-phase locking
	 - Semaphores
		 - Semaphores can be used for mutual exclusion
		 - Signal increments, Wait decrements (automatically)
		 - Wait blocks when semaphore = 0
		 - Any thread with access to the semaphore can signal / wait
	 - Summary
		 - Concurrent programming improves performance
		 - Can use processes or threads
		 - Challenging as need to deal with race conditions
		 - Using Mutex / Semaphores help


- #### Storage Management
- Persistent Storage
	- Persistent
		- RAM is volatile, if power goes we lose data
		- Need to persist data for certain use cases
		- Magnetic Tape, HDD, SSD, Flash
	- HDD
		- consists of platters, heads, tracks and sectors
		- Geometrical sector vs disk sector
		- The OS knows the physical layout of the HDD
		- Traditionally the OS addressed using CHS method,
			- Cylinder / Head / Sector
	- LBA
		- Logical block addressing
		- The entire disk is an array of blocks
		- Disk controller does the "Translation"
	- SSD
		- SSD uses NAND Technology
		- Physical page (4 KiB, 16 KiB etc.)
		- Physical block (collection of pages)
		- Min read/write is page, erase by block
		- Logical block maps to pages (Flash translation layer)
		- SSD Write
			- We find a free physical block and map it
			- No update in SSD, its a remove and add
			- SSD Write Amplification
		- Wear leveling
			- NAND cells have write limit
				- Write endurance / program
			- Cold vs hold pages
				- Page written once and never touched
				- While other pages are updated all the time
			- Some pages will die before others
		- Over provisioning
			- SSD over-provision an area for GC/WL
	- We need persisted storage
	- Storage is abstracted as blocks
	- The OS access logical blocks
- File Systems (Layer above storage)
	- An abstraction above present storage
	- Users like files / directories
	- Writing and reading to a file translates to blocks
	- Promotes caching
	- Must allocate a block (1 or more LBAs)
	- file system block - collection of LBAs
	- Examples of File systems
		- FAT (FAT16, FAT32)
		- NTFS
		- APFS (Apple File System)
		- EXT4
		- XFS
		- btrfs
	- Terminologies
		- PBA - Physical block address - internal to the drive , aka physical sector size
		- LBA - Logical block address - exposed to OS, aka logical sector size
		- File system block size
		- 1 PBA -> 1 or more LBAs
		- 1 FS block = 1 or more LBAs
	- `lsblk -o NAME,PHY-SEC,LOG-SEC`
	- FAT32
		- File allocation table
		- Basic idea is Array of 32 bit integers
		- The index is the LBA (or logical sector traditionally)
		- The content is the next LBA, until we reach end
		- 32 bit is really 28 because we need to reserve some bits
		- Cluster is a logical grouping of LBAs
		- Clustering creates more internal fragmentation, wasted space, can't be used by others.
	- Blocks everywhere
	- OS page cache
		- File system blocks read from disk are cached
		- Block number maps to virtual memory page
		- FS block <= OS VM Page (often)
		- Reads  checks the cache first then disk and updates cache
		- Writes go to the cache first, then disk
		- Block number maps to LBAs
	- `filefrag -v test-1.pem`
	- inodes and block information used by Linux or OS for the file management
	- file modes
		- O_APPEND
		- O_DIRECT
		- O_SYNC
	- Partitions
		- Disks are exposed as big array of LBAs
		- Partitions start from LBA and end in an LBA
		- Provides logical segmentation
		- Each partition can have its own FS
		- Each FS different block size (cluster)
	- Partition alignment
	- Summary
		- File systems exposes files and directories
		- Itself has a structure and storage
		- Linked to the OS page cache
		- Translation of POSIX read, fs block, to pages
- What really happens in a file IO ?
	- POSIX
		- standard UNIX based system API calls for Linux
	- So many layers
	- Translation of POSIX read, fs block, to pages
	- Page cache/delayed
- Demo
	- lsblk command line tool 
	- fdisk
	- partition create / delete, alignment
	- mount unmount disk part
	- namespace & cgroup

- #### Socket Management
- #### More OS Concepts



- Everything in Linux is file and everything in Windows is Object

#### Hands On
- Memory management and analysis with c code in Linux (http://geeksforgeeks.org/structure-member-alignment-padding-and-data-packing/)
- Linux file system and its architecture
- DMA signals & DMA Attacks
- ELF file in linux
- task_struct in linux for PCB
- Thread implementation in Kernel
- Why and how threads are not secure / safe ?
- Postgres processes & its architecture
- pg_bouncer & how does multiple query on single client connection works, does it have query ID mechanism ?
- Copy On Write mechanism
- Python CoW bug
- Scheduling algorithm walk through and implement by own
- libuv for NodeJS, IOuring etc
- mutex and use in CPP / Go to avoid threading issues
- Disk controller and its usage
- File system page cache
- De fragmentation in hard drive etc
- 
