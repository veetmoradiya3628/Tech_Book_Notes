
- Database Workloads
	- On-Line Transaction Processing (OLTP)
	- On-Line Analytical Processing (OLAP)
	- Hybrid Transaction + Analytical Processing (HTAP)
- The relational model does not specify that the DBMS must store all a tuple's attributes together in a single page.
- This may not actually be the best layout for some of the workloads.
- Storage Models
	1. N-ary storage model (NSM)
	2. Decomposition Storage model (DSM)
	3. Hybrid Storage model (PAX)

1. N-Ary Storage model
	- The DBMS stores (almost) all attributes for a single tuple contiguously in a single page. 
	- Commonly knows as raw storage.
	- The tuple's record id (page#, slot#) is how the DBMS uniquely identifies a physical tuple.
	- Adv
		- Fast inserts, updates and deletes
		- good for queries that need the entire tuple (OLTP)
		- Can use index-oriented physical storage for clustering
	- Dis. Adv
		- Not good for scanning large portions of the table and/or a subset of the attributes
		- Terrible memory locality in access patterns.
		- Not ideal for compression because of multiple value domains within a single page.

2. Decomposition Storage Model
	- Stores a single attribute for all tuples contiguously in a block of data.
	- Also known as a "column store"
	- DBMS is responsible for combining, splitting a tuple's attributes when reading / writing.
	- Stores attributes and meta-data in separate arrays of fixed-length values.
	- Maintain separate pages per attribute with a dedicated header area for meta-data about entire column.
	- Tuple identification (don't do this)
		- Fixed-length offsets
		- Embedded tuple Ids
	- variable length data to use dictionary compression.
	- Adv.
		- Reduces the amount wasted I/O per query because the DBMS only reads the data that is needs.
		- Better data compression.
	- Dis. Adv
		- Slow for point queries, inserts, updates and deletes because of tuple splitting/stitching/reorganization.

3. PAX Storage Model 
	- Partition Attributes Across (PAX) is a hybrid storage model that vertically partitions attributes within a database page.
	- The goal is to get the benefits of faster processing on columnar storage while retaining the spatial locality benefits of row storage.
	- Idea
		- Horizontally partition data into row groups. Then vertically partition their attributes into column chunks.
		- Global meta-data directory contains offsets to the file's row groups.
			- This is stored in the footer if the file is immutable (Parquet, Orc).
		- Each row group contains its own meta-data header about its contents.

- I/O is the main bottleneck if the DBMS fetches data from disk during query execution.
- The DBMS can compress pages to increase the utility of the data moved per I/O operation.
- Key trade-off is speed vs. compression ratio
- late materialization technique
- Compression granularity
	- Block level
	- Tuple level
	- Attribute level
	- Column level
- Ideally we want the DBMS to operate on compressed data without decompressing it first.
- Columnar compressions
	- Run-length encoding
	- Bit-packing encoding 
	- Bitmap encoding
	- Delta/Frame-of-Reference encoding
	- Incremental encoding
	- Dictionary encoding
- Summary
	- It is important to choose the right storage model for thee target workload:
		- OLTP - Row storage
		- OLAP - Column storage
	- DBMSs can combine different approaches for even better compression
	- Dictionary encoding is probably the most useful scheme because it does not require pre-sorting.

