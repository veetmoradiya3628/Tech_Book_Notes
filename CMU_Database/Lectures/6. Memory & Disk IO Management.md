
- Database storage
	- Spatial Control
	- Temporal Control

- Buffer pool manager
	- Memory region organized as an array of fixed-size pages.
	- An array entry is called a frame.
	- When the DBMS requests a page, an exact copy is placed into one of these frames.
	- Dirty pages are buffered and not written to disk immediately. (Write-back cache)
	- Page table : keeps track of pages that are currently in memory.
	- Additional meta-data :
		- Dirty flag
		- Pin/reference counter
		- Access tracking information.
- Locks vs. Latches
	- Locks
		- Protects the database's logical contents from other transactions
		- Held for transaction duration.
		- Need to be able to rollback changes.
	- Latches (Mutex)
		- Protects the critical sections of the DBMS's internal data structure from other threads.
		- Held for operation duration.
		- Do not need to be able to rollback changes.
- Page Table (on memory) vs. Page Directory (on disk)
- OS mmap (memory mapping)
	- mmap IO problems
		- Transaction safety
		- I/O stalls
		- Error handling
		- Performance issues
- Buffer replacement policies
	- When the DBMS needs to free up a frame to make room for a new page, it must decide which page to evict from the buffer pool.
	- Goal :
		- Correctness
		- Accuracy
		- Speed
		- Meta-data overhead
	1. LRU - Least recently used
		- Maintain a single timestamp of when each page was last accessed. When the DBMS needs to evict a page, select the one with the oldest timestamp.
		- Keep the pages in sorted order to reduce the search time on eviction.
		- clock with reference bit used as an alternative to timestamp ordering.
	-  sequential flooding issue in database
	- LRU-K
		- Track the history of last K references to each page as timestamps and compute the interval between subsequent accesses.
		- Use this history to estimate the next time that page is going to be accessed.
	- Approximate LRU-K
	- Localization
		- circular ring buffer
	- Priority hints
- Dirty pages
	- Fast path: if a page in the buffer pool is not dirty, then the DBMS can simply "drop" it.
	- Slow path: if a page is dirty, then the DBMS must write back to disk to ensure that its changes are persisted.
	- Trade off between above 2 ways.
- Background writing
	- The DBMS can periodically walk through the page table and write dirty pages to disk.
	- When a dirty page is safely written, the DBMS can either evict the page or just unset the dirty flag.
	- Need to be careful that the system doesn't write dirty pages before their log records are written.
- Disk I/O scheduling
	- The DBMS maintain internal queue(s) to track page read/write requests from the entire system.
	- Compute priorities based on several factors:
		- Sequential vs. Random IO
		- Critical path vs. Background path
		- Table vs Index vs Log vs Ephemeral
		- Transaction information
		- User-based SLAs
	- OS Page cache
		- Most DBMSs use direct I/O to bypass the OS's cache.
	- fsync vs fwrite system call, what happens ?
- Buffer pool optimizations
	- Multiple Buffer pools
		- ObjectId or Hashing for selecting buffer pool
	- Pre-fetching
	- Scan sharing
		- scan sharing
	- Buffer pool bypass
		- light scans

- The DBMS can almost always manage memory better than the OS.
- Leverage the semantics about the query plan to make better decisions:
	- Evictions
	- Allocations
	- Pre-fetching



